# Appendix A, Section 7.2: Standards Development and Governance

## Overview

Technical standards establish common frameworks, definitions, and requirements. AI evaluation standards are emerging, and understanding the standards landscape helps organizations navigate compliance requirements and contribute to standards development.

Standards provide coordination benefitsâ€”common frameworks enable comparison, communication, and quality assurance. For AI evaluation, emerging standards will shape how AI is assessed, governed, and deployed.

---

## Core Concepts

### Types of Standards

**De jure standards** are established through formal processes:
- Standards development organizations (SDOs) like ISO, IEEE, NIST
- Consensus-based processes with stakeholder participation
- Formal approval and publication
- Often referenced in regulation

**De facto standards** emerge from market adoption:
- Widely used approaches become standard practice
- May not have formal documentation
- May later be formalized as de jure standards
- Example: Common benchmark suites becoming industry norm

**Mandatory vs. voluntary**:
- Some standards are required by law or regulation
- Others are voluntary guidelines organizations can choose to follow
- The same standard may be voluntary in one jurisdiction, mandatory in another

**Performance vs. prescriptive**:
- Performance standards specify what must be achieved (outcomes)
- Prescriptive standards specify how to achieve it (methods)
- Performance standards allow flexibility; prescriptive standards ensure consistency

### Standards Development Organizations

Key SDOs for AI:

**NIST** (National Institute of Standards and Technology):
- Developed the AI Risk Management Framework
- Conducts AI evaluation research
- US government technical standards body

**ISO** (International Organization for Standardization):
- ISO/IEC JTC 1/SC 42 develops AI standards
- International scope
- Consensus-based process

**IEEE** (Institute of Electrical and Electronics Engineers):
- Standards for AI ethics, transparency, and related topics
- Technical community-driven

**Industry consortia**: Various industry groups developing AI governance frameworks.

**Standards development processes** typically involve:
1. Identification of need
2. Formation of working groups
3. Drafting and iteration
4. Consensus building among stakeholders
5. Public comment periods
6. Formal approval and publication
7. Ongoing maintenance and revision

### Conformity Assessment

Conformity assessment determines whether products/services meet standards:

**Self-declaration**: Organization claims compliance based on internal assessment.

**Second-party assessment**: Customer evaluates supplier compliance.

**Third-party certification**: Independent body evaluates and certifies compliance.

**Accreditation**: Recognition of competence of conformity assessment bodies. Who certifies the certifiers?

For AI, conformity assessment asks:
- How do you demonstrate compliance with AI standards?
- Who is qualified to assess compliance?
- What evidence is required?

These questions are actively being worked out as standards mature.

### Standards and Innovation

Standardization has complex effects on innovation:

**Too early**: Locks in immature approaches. May stifle innovation by freezing current practices.

**Too late**: Misses opportunity for coordination. Market fragmentation; incompatibility.

**Dynamic standards**: Versioned standards that can evolve. Balance stability with adaptability.

**Reference architectures**: General frameworks that allow flexibility in implementation.

For AI, the timing question is acute:
- Standards developed now may not fit tomorrow's AI
- But lack of standards creates uncertainty and inconsistency
- The field is changing faster than standards can keep up

### Current AI Standards Landscape

**NIST AI Risk Management Framework**:
- Voluntary framework for managing AI risks
- Includes evaluation guidance
- Widely referenced in US contexts
- Integrates with existing risk management practices

**ISO/IEC AI standards** in development:
- AI management systems
- Trustworthiness characteristics
- Data quality for AI
- Governance implications

**EU AI Act**:
- Regulatory framework with conformity assessment requirements
- High-risk AI systems require compliance demonstration
- Will require standards for compliance

**Industry frameworks**:
- Various consortia developing AI governance frameworks
- Some may become de facto standards
- Varying levels of rigor and adoption

### Implementation of Standards

Standards only create value when implemented:

**Gap analysis**: Assess current state against standard requirements.

**Remediation**: Address gaps to achieve compliance.

**Documentation**: Create evidence of compliance.

**Audit**: Internal and/or external verification.

**Continuous improvement**: Maintain and improve compliance over time.

For AI, implementation challenges include:
- Standards may not map clearly to current practices
- Technical requirements may be ambiguous for AI
- Expertise for implementation may be scarce
- Changing AI may require continuous re-assessment

---

## What Transfers to AI Evaluation

**Standards awareness**: Know what standards exist and are emerging. Stay informed about the evolving landscape.

**Conformity assessment**: Understand how compliance will be demonstrated. Prepare for assessment requirements.

**Timing awareness**: AI standards are still developing; don't wait, but expect evolution.

**Process participation**: Organizations can participate in standards development to shape outcomes.

---

## What Breaks for Generative AI

**Stable technology**: Standards assume relatively stable technology to standardize. AI changes faster than standards processes.

**Clear definitions**: Standards require clear definitions. AI concepts are contested and evolving.

**Established practices**: Standards often codify best practices. Best practices for AI are still emerging.

**Consensus**: Standards require consensus. AI governance views vary significantly.

---

## What Can Be Adapted

**Risk-based approaches** that don't require specifying all details. Focus on outcomes rather than prescribing methods.

**Adaptive standards** with built-in review and revision cycles.

**Tiered requirements** that scale with AI risk levels.

**Principle-based standards** that can accommodate technological change.

---

## Implications for AI Evaluation

**Engage with emerging standards** (NIST AI RMF, ISO, etc.). Understand requirements; participate where appropriate.

**Recognize standards are developing**; don't wait for them, but expect evolution. Current practices should anticipate compliance requirements.

**Consider contributing** to standards development. Shape standards rather than just following them.

**Understand conformity assessment requirements** as they emerge. Prepare for compliance demonstration.

**Build flexible evaluation practices** that can adapt to evolving standards.

---

## Key References

- **NIST AI Risk Management Framework.** US government AI risk management guidance.

- **ISO/IEC JTC 1/SC 42.** AI standards development at ISO.

- **EU Artificial Intelligence Act.** European regulatory framework for AI.

- **IEEE 7000 series.** Ethics-related AI standards.

- **OECD AI Principles.** International policy principles for AI.

---

## Connections to Other Sections

Standards connect to several other disciplines covered in this appendix:

- **Section 7.1 (Metrology)** provides measurement science foundations for standardization.

- **Section 4.4 (Audit)** addresses assurance and conformity assessment.

- **Section 4.1 (Risk Analysis)** informs risk-based standards approaches.

- **Section 6.1 (AI Safety Evaluation)** addresses emerging AI-specific evaluation approaches.

- **Section 1.2 (Systems T&E)** addresses defense standards context.

---

*[End of Section 7.2]*
