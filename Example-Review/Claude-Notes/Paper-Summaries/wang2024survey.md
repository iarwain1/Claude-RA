# A Survey on Large Language Model based Autonomous Agents

**Authors:** Wang, Lei; Ma, Chen; Feng, Xueyang
**Year:** 2024
**URL:** https://arxiv.org/abs/2308.11432

## Key Contributions
- Comprehensive taxonomy of LLM-based agent architectures
- Analysis of agent construction approaches (fine-tuning vs prompting)
- Survey of evaluation methods and benchmarks
- Discussion of applications across domains

## Methodology
Systematic literature review covering papers from 2022-2024 on LLM agents.

## Key Findings
- Agent architectures typically include: profile, memory, planning, and action modules
- Memory systems are crucial for maintaining context and learning
- Planning can be done with or without feedback loops
- Tool use significantly extends agent capabilities

## Agent Architecture Components
1. **Profile Module**: Defines agent identity and role
2. **Memory Module**: Short-term (context) and long-term (retrieval) memory
3. **Planning Module**: Task decomposition and strategy
4. **Action Module**: Tool use and environment interaction

## Relevance to Review
Foundational survey paper - provides taxonomy and vocabulary for understanding the field. Essential reading for any LLM agents literature review.

## Citations to Follow
- Significant Objects paper (agent profiles)
- Generative Agents paper (memory architectures)
- HuggingGPT (tool use)

## Questions/Notes
- The taxonomy is useful but may miss some emerging patterns
- Would benefit from more discussion of failure modes
- Security and safety concerns could be covered more deeply
