# Appendix A, Section 8.5: Terminology Crosswalk

## Overview

Different disciplines use different terms for similar or related concepts. This crosswalk maps common concepts across disciplines to help readers connect familiar terminology to unfamiliar fields.

This section is primarily reference material—tables mapping equivalent terms across disciplines.

---

## Accuracy and Error

| Discipline | Term | Meaning |
|------------|------|---------|
| Traditional ML | Accuracy | Proportion of correct predictions |
| Traditional ML | Error rate | Proportion of incorrect predictions |
| Metrology | Accuracy | Closeness to true value (combining trueness and precision) |
| Metrology | Trueness | Systematic closeness to true value |
| Metrology | Precision | Repeatability of measurements |
| Software Testing | Defect | Software behavior contrary to specification |
| Quality Management | Defect | Unit that doesn't conform to specifications |
| AI | Hallucination | AI generating false information presented as true |

---

## Reliability and Consistency

| Discipline | Term | Meaning |
|------------|------|---------|
| Psychometrics | Reliability | Consistency of measurement across occasions, raters, items |
| Reliability Engineering | Reliability | Probability of successful operation over time |
| Software Engineering | Reliability | Probability of failure-free operation |
| Quality Management | Consistency | Producing similar outputs over time |
| AI | Reproducibility | Same input producing same/similar output |

---

## Validity and Effectiveness

| Discipline | Term | Meaning |
|------------|------|---------|
| Psychometrics | Validity | Whether measure assesses intended construct |
| Experimental Design | Internal validity | Whether conclusions about causation are warranted |
| Experimental Design | External validity | Whether findings generalize beyond study |
| Experimental Design | Construct validity | Whether operationalization captures concept |
| Systems T&E | Effectiveness | Degree to which system accomplishes mission |
| Psychometrics | Criterion validity | Whether measure predicts relevant outcomes |
| Systems T&E | MOE | Measure of Effectiveness—mission outcome metrics |

---

## Performance and Capability

| Discipline | Term | Meaning |
|------------|------|---------|
| Systems T&E | Performance | Technical parameter values (speed, accuracy, etc.) |
| Systems T&E | MOP | Measure of Performance—technical parameters |
| I-O Psychology | Performance | Work output quality and quantity |
| AI Safety | Capability | What the model can do (including dangerous capabilities) |
| AI Evaluation | Benchmark score | Performance on standardized evaluation |
| Human Factors | Human performance | Quality of human task execution |

---

## Testing Types

| Discipline | Term | Meaning |
|------------|------|---------|
| Software Testing | Unit testing | Testing individual components |
| Software Testing | Integration testing | Testing component interactions |
| Software Testing | System testing | Testing complete system |
| Systems T&E | Developmental testing (DT) | Testing during development |
| Systems T&E | Operational testing (OT) | Testing under realistic conditions |
| Clinical Trials | Phase I, II, III | Staged testing with increasing scale and rigor |
| AI Safety | Red teaming | Adversarial testing to find failures |

---

## Risk and Hazard

| Discipline | Term | Meaning |
|------------|------|---------|
| Risk Analysis | Risk | Probability × Consequence |
| Risk Analysis | Hazard | Condition that could cause harm |
| Safety Engineering | Hazard | Condition that could lead to accident |
| Safety Engineering | Risk | Function of hazard, exposure, and consequence |
| Cybersecurity | Threat | Potential source of harm |
| Cybersecurity | Vulnerability | Weakness that can be exploited |
| AI Safety | Dangerous capability | AI ability that could enable harm |

---

## Independence and Separation

| Discipline | Term | Meaning |
|------------|------|---------|
| Audit | Independence | Auditor separate from entity being audited |
| Systems T&E | Independent evaluation | Evaluation by party independent of developer |
| Experimental Design | Random assignment | Unpredictable assignment to conditions |
| Experimental Design | Blinding | Hiding condition assignment from participants/researchers |
| Clinical Trials | Double-blind | Neither participant nor administrator knows assignment |

---

## Quality and Assurance

| Discipline | Term | Meaning |
|------------|------|---------|
| Quality Management | Quality | Conformance to requirements |
| Quality Management | Assurance | Confidence that quality requirements will be met |
| Audit | Assurance | Confidence that claims are accurate |
| Safety Engineering | Safety case | Structured argument that system is safe |
| AI Safety | Safety case | Structured argument for AI safety |
| Audit | Reasonable assurance | High but not absolute confidence |

---

## Human-AI Interaction Concepts

| Discipline | Term | Meaning |
|------------|------|---------|
| Human Factors | Trust calibration | Matching trust to actual system reliability |
| Human Factors | Automation bias | Uncritical acceptance of automation |
| JDM | Algorithm aversion | Resistance to algorithmic advice |
| JDM | Algorithm appreciation | Over-reliance on algorithmic advice |
| Human Factors | Complacency | Inappropriate trust in automation |
| Human Factors | Disuse | Not using helpful automation |
| Human Factors | Situation awareness | Understanding of current state and future trajectory |
| HCI | Mental model | User's understanding of how system works |

---

## Evaluation Approaches

| Discipline | Term | Meaning |
|------------|------|---------|
| Program Evaluation | Formative evaluation | Evaluation to improve during implementation |
| Program Evaluation | Summative evaluation | Evaluation to judge overall effectiveness |
| Program Evaluation | Process evaluation | Did intervention occur as planned? |
| Program Evaluation | Outcome evaluation | Did desired effects occur? |
| Clinical Trials | Efficacy | Effect under ideal conditions |
| Clinical Trials | Effectiveness | Effect under real-world conditions |
| Program Evaluation | Implementation fidelity | Was intervention delivered as designed? |

---

## Measurement Concepts

| Discipline | Term | Meaning |
|------------|------|---------|
| Psychometrics | Inter-rater reliability | Agreement among different judges |
| Metrology | Uncertainty | Range within which true value lies |
| Metrology | Traceability | Chain connecting measurement to standards |
| Metrology | Calibration | Verifying instrument against standards |
| I-O Psychology | Criterion deficiency | What's missing from performance measure |
| I-O Psychology | Criterion contamination | Irrelevant factors affecting performance measure |

---

## Using This Crosswalk

When encountering unfamiliar terminology:
1. Look up the term in this crosswalk
2. Identify the source discipline
3. Understand the disciplinary context
4. Translate to familiar terminology
5. Note subtle differences in meaning across disciplines

When communicating across disciplines:
1. Be explicit about which meaning you intend
2. Define terms when ambiguity is possible
3. Use disciplinary context to clarify
4. Recognize that "same term, different meaning" is common

---

*[End of Section 8.5]*
