# Agent AI: Surveying the Horizons of Multimodal Interaction

**arXiv:** https://arxiv.org/abs/2401.03568
**Authors:** Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong, Jae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Yejin Choi, Katsushi Ikeuchi, Hoi Vo, Li Fei-Fei, Jianfeng Gao (Microsoft, Stanford, etc.)
**Date:** 2024-01-07 (v1), revised 2024-01-25 (v2)

## Abstract

Multi-modal AI systems will likely become a ubiquitous presence in our everyday lives. A promising approach to making these systems more interactive is to embody them as agents within physical and virtual environments.

The authors define "Agent AI" as a class of interactive systems that can:
- Perceive visual stimuli, language inputs, and other environmentally-grounded data
- Produce meaningful embodied actions

They explore systems that improve agents based on next-embodied action prediction by incorporating external knowledge, multi-sensory inputs, and human feedback.

The paper argues that developing agentic AI systems in grounded environments can mitigate hallucinations of large foundation models and their tendency to generate environmentally incorrect outputs.

## Claude Summary

This survey from Microsoft Research and Stanford defines the emerging field of "Agent AI" - multimodal systems that act in physical and virtual environments.

**Key vision**:
- AI agents as ubiquitous interactive systems
- Embodiment as a solution to hallucination (grounding in environment)
- Multi-sensory perception â†’ embodied action

**Technical components**:
- Foundation models as building blocks
- Environmental grounding for context awareness
- Human feedback integration

The paper envisions a future where people create virtual environments and interact with embodied AI agents.

## Relevance

Important survey for understanding the Agent AI landscape. Connects multimodal AI, embodiment, and foundation models. Useful for understanding where the field is heading.
