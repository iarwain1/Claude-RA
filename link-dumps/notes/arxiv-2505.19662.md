# FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks

**arXiv:** [2505.19662](https://arxiv.org/abs/2505.19662)
**Authors:** Atsunori Moteki, Shoichi Masui, Fan Yang, Yueqi Song, Yonatan Bisk, et al. (11 total)
**Date:** 2025-05-26
**Categories:** cs.AI, cs.CV

## Abstract

This paper proposes FieldWorkArena, a benchmark for agentic AI targeting real-world field work. With the recent increase in demand for agentic AI, they are required to monitor and report safety and health incidents, as well as manufacturing-related incidents, that may occur in real-world work environments. Existing agentic AI benchmarks have been limited to evaluating web tasks and are insufficient for evaluating agents in real-world work environments, where complexity increases significantly. In this paper, we define a new action space that agentic AI should possess for real world work environment benchmarks and improve the evaluation function from previous methods to assess the performance of agentic AI in diverse real-world tasks. The dataset consists of videos captured on-site and documents actually used in factories and warehouses, and tasks were created based on interviews with on-site workers and managers. Evaluation results confirmed that performance evaluation considering the characteristics of Multimodal LLM (MLLM) such as GPT-4o is feasible. Additionally, the effectiveness and limitations of the proposed new evaluation method were identified. The complete dataset (HuggingFace) and evaluation program (GitHub) can be downloaded from the following website: https://en-documents.research.global.fujitsu.com/fieldworkarena/.

---
*Metadata fetched via arxiv API on 2025-12-31*
