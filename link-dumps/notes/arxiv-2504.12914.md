# In Which Areas of Technical AI Safety Could Geopolitical Rivals Cooperate?

**arXiv:** [2504.12914](https://arxiv.org/abs/2504.12914)
**Authors:** Ben Bucknall, Saad Siddiqui, Lara Thurnherr, Conor McGurk, Ben Harack, et al. (22 total)
**Date:** 2025-04-17
**Categories:** cs.CY

## Abstract

International cooperation is common in AI research, including between geopolitical rivals. While many experts advocate for greater international cooperation on AI safety to address shared global risks, some view cooperation on AI with suspicion, arguing that it can pose unacceptable risks to national security. However, the extent to which cooperation on AI safety poses such risks, as well as provides benefits, depends on the specific area of cooperation. In this paper, we consider technical factors that impact the risks of international cooperation on AI safety research, focusing on the degree to which such cooperation can advance dangerous capabilities, result in the sharing of sensitive information, or provide opportunities for harm. We begin by why nations historically cooperate on strategic technologies and analyse current US-China cooperation in AI as a case study. We further argue that existing frameworks for managing associated risks can be supplemented with consideration of key risks specific to cooperation on technical AI safety research. Through our analysis, we find that research into AI verification mechanisms and shared protocols may be suitable areas for such cooperation. Through this analysis we aim to help researchers and governments identify and mitigate the risks of international cooperation on AI safety research, so that the benefits of cooperation can be fully realised.

---
*Metadata fetched via arxiv API on 2025-12-31*
