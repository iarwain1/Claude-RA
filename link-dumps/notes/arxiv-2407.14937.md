# Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs)

**arXiv:** [2407.14937](https://arxiv.org/abs/2407.14937)
**Authors:** Apurv Verma, Satyapriya Krishna, Sebastian Gehrmann, Madhavan Seshadri, et al.
**Date:** 2024-07-20

## Abstract

Creating secure and resilient applications with large language models (LLM) requires anticipating, adjusting to, and countering unforeseen threats. This paper presents a detailed threat model and provides a systematization of knowledge (SoK) of red-teaming attacks on LLMs. The authors develop a taxonomy of attacks based on the stages of the LLM development and deployment process.
