# Writing as a testbed for open ended agents

**arXiv:** [2503.19711](https://arxiv.org/abs/2503.19711)
**Authors:** Sian Gooding, Lucia Lopez-Rivilla, Edward Grefenstette
**Date:** 2025-03-25
**Categories:** cs.CL, cs.AI, cs.HC

## Abstract

Open-ended tasks are particularly challenging for LLMs due to the vast solution space, demanding both expansive exploration and adaptable strategies, especially when success lacks a clear, objective definition. Writing, with its vast solution space and subjective evaluation criteria, provides a compelling testbed for studying such problems. In this paper, we investigate the potential of LLMs to act as collaborative co-writers, capable of suggesting and implementing text improvements autonomously. We analyse three prominent LLMs - Gemini 1.5 Pro, Claude 3.5 Sonnet, and GPT-4o - focusing on how their action diversity, human alignment, and iterative improvement capabilities impact overall performance. This work establishes a framework for benchmarking autonomous writing agents and, more broadly, highlights fundamental challenges and potential solutions for building systems capable of excelling in diverse open-ended domains.

---
*Metadata fetched via arxiv API on 2025-12-31*
