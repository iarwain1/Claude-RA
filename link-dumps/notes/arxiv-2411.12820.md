# Declare and Justify: Explicit assumptions in AI evaluations are necessary for effective regulation

**arXiv:** [2411.12820](https://arxiv.org/abs/2411.12820)
**Authors:** Peter Barnett, Lisa Thiergart
**Date:** 2024-11-19

## Abstract

The authors argue that AI regulation should require developers to explicitly identify and justify key underlying assumptions about evaluations as part of their case for safety. The paper identifies core assumptions in AI evaluations such as comprehensive threat modeling, proxy task validity, and adequate capability elicitation. If regulation is to be based on evaluations, it should require that AI development be halted if evaluations demonstrate unacceptable danger or if these assumptions cannot be adequately justified.
