# On the Robustness of Kolmogorov-Arnold Networks: An Adversarial Perspective

**arXiv:** [2408.13809](https://arxiv.org/abs/2408.13809)
**Authors:** Tal Alter, Raz Lapid, Moshe Sipper
**Date:** 2024-08-25
**Categories:** cs.CV, cs.CR

## Abstract

Kolmogorov-Arnold Networks (KANs) have recently emerged as a novel approach to function approximation, demonstrating remarkable potential in various domains. Despite their theoretical promise, the robustness of KANs under adversarial conditions has yet to be thoroughly examined. In this paper we explore the adversarial robustness of KANs, with a particular focus on image classification tasks. We assess the performance of KANs against standard white box and black-box adversarial attacks, comparing their resilience to that of established neural network architectures. Our experimental evaluation encompasses a variety of standard image classification benchmark datasets and investigates both fully connected and convolutional neural network architectures, of three sizes: small, medium, and large. We conclude that small- and medium-sized KANs (either fully connected or convolutional) are not consistently more robust than their standard counterparts, but that large-sized KANs are, by and large, more robust. This comprehensive evaluation of KANs in adversarial scenarios offers the first in-depth analysis of KAN security, laying the groundwork for future research in this emerging field.

---
*Metadata fetched via arxiv API on 2025-12-31*
