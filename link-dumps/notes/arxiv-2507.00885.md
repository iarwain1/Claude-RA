# Scaling Laws Are Unreliable for Downstream Tasks: A Reality Check

**arXiv:** [2507.00885](https://arxiv.org/abs/2507.00885)
**Authors:** Nicholas Lourie, Michael Y. Hu, Kyunghyun Cho
**Date:** 2025-07-01
**Categories:** cs.CL, cs.LG

## Abstract

Downstream scaling laws aim to predict task performance at larger scales from the model's performance at smaller scales. Whether such prediction should be possible is unclear: some works discover clear linear scaling trends after simple transformations of the performance metric, whereas others point out fundamental challenges to downstream scaling laws, such as emergence and inverse scaling. In this work, we conduct a meta-analysis of existing data on downstream scaling laws, and we find that predictable scaling only occurs in a minority of cases: 39% of the time. Moreover, seemingly benign changes to the experimental setting can completely change the scaling behavior. Our analysis underscores the need to understand the conditions under which scaling laws succeed. To accurately model the relationship between pretraining loss and task performance, we must embrace the cases in which scaling behavior deviates from linear trends.

---
*Metadata fetched via arxiv API on 2025-12-31*
