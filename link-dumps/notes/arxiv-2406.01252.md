# Towards Scalable Automated Alignment of LLMs: A Survey

**arXiv:** https://arxiv.org/abs/2406.01252
**Authors:** Boxi Cao, Keming Lu, Xinyu Lu, Jiawei Chen, Mengjie Ren, Hao Xiang, Peilin Liu, Yaojie Lu, Ben He, Xianpei Han, Le Sun, Hongyu Lin, Bowen Yu
**Date:** 2024-06-03 (v1), revised 2024-09-03 (v3)

## Abstract

Alignment is the most critical step in building large language models (LLMs) that meet human needs. With the rapid development of LLMs gradually surpassing human capabilities, traditional alignment methods based on human-annotation are increasingly unable to meet scalability demands. Therefore, there is an urgent need to explore new sources of automated alignment signals and technical approaches.

The paper systematically reviews the recently emerging methods of automated alignment, attempting to explore how to achieve effective, scalable, automated alignment once the capabilities of LLMs exceed those of humans.

Specifically, the authors categorize existing automated alignment methods into 4 major categories based on the sources of alignment signals and discuss the current status and potential development of each category. Additionally, they explore the underlying mechanisms that enable automated alignment and discuss the essential factors that make automated alignment technologies feasible.

## Claude Summary

This survey addresses the "scalable oversight" problem: how do you align AI systems that are more capable than their human supervisors?

**The core challenge**: Human annotation doesn't scale, and becomes impossible when models exceed human capability.

**Four categories of automated alignment signals** (to be explored):
1. Self-alignment / Constitutional AI approaches
2. AI feedback / debate methods
3. Reward model bootstrapping
4. Other automated supervision techniques

The paper systematically reviews approaches to this fundamental problem in AI safety.

## Relevance

Essential for AI alignment research. Addresses the crucial scalability challenge in alignment - how to align superhuman systems. Important for understanding the landscape of automated alignment approaches.
