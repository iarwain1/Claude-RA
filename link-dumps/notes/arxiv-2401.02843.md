# Thousands of AI Authors on the Future of AI

**arXiv:** https://arxiv.org/abs/2401.02843
**Authors:** Katja Grace, Harlan Stewart, Julia Fabienne Sandkühler, Stephen Thomas, Ben Weinstein-Raun, Jan Brauner, Richard C. Korzekwa (AI Impacts)
**Date:** 2024-01-05 (v1), revised 2025-10-08 (v3)

## Abstract

In the largest survey of its kind, 2,778 researchers who had published in top-tier artificial intelligence (AI) venues gave predictions on the pace of AI progress and the nature and impacts of advanced AI systems.

### Timeline Predictions

The aggregate forecasts give at least a 50% chance of AI systems achieving several milestones by 2028, including:
- Autonomously constructing a payment processing site from scratch
- Creating a song indistinguishable from a new song by a popular musician
- Autonomously downloading and fine-tuning a large language model

If science continues undisrupted:
- 10% chance of machines outperforming humans in every task by 2027
- 50% chance by 2047 (13 years earlier than 2022 survey)
- 50% chance of full job automation by 2116

### Risk Concerns

- 68.3% thought good outcomes from superhuman AI more likely than bad
- Of net optimists, 48% gave ≥5% chance of extremely bad outcomes including extinction
- 37.8%-51.4% gave ≥10% chance of human extinction from advanced AI

Top concerns (>70% substantial/extreme concern):
1. Spread of false information/deepfakes (86%)
2. Manipulation of public opinion (79%)
3. Dangerous groups making powerful tools (73%)
4. Authoritarian control (73%)
5. Worsened economic inequality (71%)

## Claude Summary

This is the definitive survey of AI researcher opinions on AI progress and risks. Key takeaways:

1. **Timelines accelerating**: 50% chance of human-level AI moved from 2060 to 2047 in just one year
2. **Expert risk concern is high**: Even optimists assign substantial probability to catastrophic outcomes
3. **Broad agreement on near-term risks**: Misinformation, manipulation, and inequality top concerns
4. **Safety research prioritization**: Broad consensus that AI safety research should be prioritized more

The survey methodology (2,778 researchers from top venues) gives it substantial weight in AI policy discussions.

## Relevance

Essential for AI governance and forecasting discussions. Provides empirical data on expert opinions about AI timelines and risks. Important for calibrating expectations about AI progress.
