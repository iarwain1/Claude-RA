# AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases

**arXiv:** [2407.12784](https://arxiv.org/abs/2407.12784)
**Authors:** Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li
**Date:** 2024-07-17

## Abstract

The authors propose AgentPoison, the first backdoor attack targeting generic and RAG-based LLM agents by poisoning their long-term memory or RAG knowledge base. AgentPoison requires no additional model training and achieves an average attack success rate higher than 80% with minimal impact on benign performance.
