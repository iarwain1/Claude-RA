# Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems

**arXiv:** [2505.23847](https://arxiv.org/abs/2505.23847)
**Authors:** Ronny Ko, Jiseong Jeong, Shuyuan Zheng, Chuan Xiao, Tae-Wan Kim, et al. (7 total)
**Date:** 2025-05-28
**Categories:** cs.CR, cs.AI

## Abstract

Large language models (LLMs) are rapidly evolving into autonomous agents that cooperate across organizational boundaries, enabling joint disaster response, supply-chain optimization, and other tasks that demand decentralized expertise without surrendering data ownership. Yet, cross-domain collaboration shatters the unified trust assumptions behind current alignment and containment techniques. An agent benign in isolation may, when receiving messages from an untrusted peer, leak secrets or violate policy, producing risks driven by emergent multi-agent dynamics rather than classical software bugs. This position paper maps the security agenda for cross-domain multi-agent LLM systems. We introduce seven categories of novel security challenges, for each of which we also present plausible attacks, security evaluation metrics, and future research guidelines.

---
*Metadata fetched via arxiv API on 2025-12-31*
