# The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing

**arXiv:** [2407.07786](https://arxiv.org/abs/2407.07786)
**Authors:** Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, et al. (12 total)
**Date:** 2024-07-10
**Categories:** cs.HC, cs.AI, cs.CY

## Abstract

Rapid progress in general-purpose AI has sparked significant interest in "red teaming," a practice of adversarial testing originating in military and cybersecurity applications. AI red teaming raises many questions about the human factor, such as how red teamers are selected, biases and blindspots in how tests are conducted, and harmful content's psychological effects on red teamers. A growing body of HCI and CSCW literature examines related practices-including data labeling, content moderation, and algorithmic auditing. However, few, if any have investigated red teaming itself. Future studies may explore topics ranging from fairness to mental health and other areas of potential harm. We aim to facilitate a community of researchers and practitioners who can begin to meet these challenges with creativity, innovation, and thoughtful reflection.

---
*Metadata fetched via arxiv API on 2025-12-31*
