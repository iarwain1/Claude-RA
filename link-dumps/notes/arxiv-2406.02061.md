# Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models

**arXiv:** [2406.02061](https://arxiv.org/abs/2406.02061)
**Authors:** Marianna Nezhurina, Lucia Cipolina-Kun, Mehdi Cherti, Jenia Jitsev
**Date:** 2024-06-04

## Abstract

Large Language Models (LLMs) are often described as instances of foundation models that possess strong generalization. The authors demonstrate a dramatic breakdown of generalization and basic reasoning of all SOTA models including GPT-4 and Claude 3 Opus, using a simple, short common sense math problem. Models express strong overconfidence in their wrong solutions while providing non-sensical explanations.
