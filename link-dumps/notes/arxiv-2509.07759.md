# A Survey of Long-Document Retrieval in the PLM and LLM Era

**arXiv:** [2509.07759](https://arxiv.org/abs/2509.07759)
**Authors:** Minghan Li, Miyang Luo, Tianrui Lv, Yishuai Zhang, Siqi Zhao, et al. (7 total)
**Date:** 2025-09-09
**Categories:** cs.IR

## Abstract

The proliferation of long-form documents presents a fundamental challenge to information retrieval (IR), as their length, dispersed evidence, and complex structures demand specialized methods beyond standard passage-level techniques. This survey provides the first comprehensive treatment of long-document retrieval (LDR), consolidating methods, challenges, and applications across three major eras. We systematize the evolution from classical lexical and early neural models to modern pre-trained (PLM) and large language models (LLMs), covering key paradigms like passage aggregation, hierarchical encoding, efficient attention, and the latest LLM-driven re-ranking and retrieval techniques. Beyond the models, we review domain-specific applications, specialized evaluation resources, and outline critical open challenges such as efficiency trade-offs, multimodal alignment, and faithfulness. This survey aims to provide both a consolidated reference and a forward-looking agenda for advancing long-document retrieval in the era of foundation models.

---
*Metadata fetched via arxiv API on 2025-12-31*
