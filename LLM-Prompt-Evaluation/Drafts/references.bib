% References for LLM Prompt Evaluation Literature Review
% Generated: 2025-12-17

% === PRACTITIONER GUIDES ===

@misc{husain2024evals,
  author = {Husain, Hamel},
  title = {Your {AI} Product Needs Evals},
  year = {2024},
  url = {https://hamel.dev/blog/posts/evals/},
  note = {Blog post}
}

@misc{husain2024llmjudge,
  author = {Husain, Hamel},
  title = {Using {LLM}-as-a-Judge For Evaluation: A Complete Guide},
  year = {2024},
  url = {https://hamel.dev/blog/posts/llm-judge/},
  note = {Blog post}
}

@misc{husain2025evalsfaq,
  author = {Husain, Hamel and Shankar, Shreya},
  title = {{AI} Evals {FAQ}},
  year = {2025},
  url = {https://hamel.dev/blog/posts/evals-faq/},
  note = {Blog post}
}

@misc{husain2025fieldguide,
  author = {Husain, Hamel},
  title = {A Field Guide to Rapidly Improving {AI} Products},
  year = {2025},
  url = {https://hamel.dev/blog/posts/field-guide/},
  note = {Blog post}
}

% === SURVEYS ===

@article{mei2025contextengineering,
  author = {Mei, Lingrui and Yao, Jiayu and Ge, Yuyao and Wang, Yiwei and Bi, Baolong and Cai, Yujun and Liu, Jiazhi and Li, Mingyu and Li, Zhong-Zhi and Zhang, Duzhen and Zhou, Chenlin and Mao, Jiayi and Xia, Tianze and Guo, Jiafeng and Liu, Shenghua},
  title = {A Survey of Context Engineering for Large Language Models},
  year = {2025},
  journal = {arXiv preprint arXiv:2507.13334},
  url = {https://arxiv.org/abs/2507.13334}
}

@article{guo2025agentbenchmark,
  author = {Guo, Jiale and Huang, Suizhi and Li, Mei and Huang, Dong and Chen, Xingsheng and Zhang, Regina and Guo, Zhijiang and Yu, Han and Yiu, Siu-Ming and Lio, Pietro and Lam, Kwok-Yan},
  title = {A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of {LLM}-Empowered Agentic System},
  year = {2025},
  journal = {arXiv preprint arXiv:2510.09721},
  url = {https://arxiv.org/abs/2510.09721}
}

@article{survey2025codeintelligence,
  author = {Yang, Jian and others},
  title = {From Code Foundation Models to Agents and Applications: A Comprehensive Survey and Practical Guide to Code Intelligence},
  year = {2025},
  journal = {arXiv preprint arXiv:2511.18538},
  url = {https://arxiv.org/abs/2511.18538}
}

% === CONTEXT ENGINEERING ===

@article{contexteng2025evolution,
  author = {Hua, Qishuo and Ye, Lyumanshan and Fu, Dayuan and Xiao, Yang and Cai, Xiaojie and Wu, Yunze and Lin, Jifan and Wang, Junfei and Liu, Pengfei},
  title = {Context Engineering 2.0: The Context of Context Engineering},
  year = {2025},
  journal = {arXiv preprint arXiv:2510.26493},
  url = {https://arxiv.org/abs/2510.26493}
}

@article{ace2025contextengineering,
  author = {Zhang, Qizheng and Hu, Changran and Upasani, Shubhangi and Ma, Boyuan and Hong, Fenglu and Kamanuru, Vamsidhar and Rainton, Jay and Wu, Chen and Ji, Mengmeng and Li, Hanchen and Thakker, Urmish and Zou, James and Olukotun, Kunle},
  title = {Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models},
  year = {2025},
  journal = {arXiv preprint arXiv:2510.04618},
  url = {https://arxiv.org/abs/2510.04618}
}

% === PROMPT OPTIMIZATION ===

@article{promptcot2025scaling,
  author = {Zhao, Xueliang and Wu, Wei and Guan, Jian and Gong, Zhuocheng and Kong, Lingpeng},
  title = {{PromptCoT} 2.0: Scaling Prompt Synthesis for Large Language Model Reasoning},
  year = {2025},
  journal = {arXiv preprint arXiv:2509.19894},
  url = {https://arxiv.org/abs/2509.19894}
}

% === BENCHMARKS ===

@article{innogym2025benchmark,
  author = {Zhang, Jintian and others},
  title = {{InnoGym}: Benchmarking the Innovation Potential of {AI} Agents},
  year = {2025},
  journal = {arXiv preprint arXiv:2512.01822},
  url = {https://arxiv.org/abs/2512.01822}
}

% === EMPIRICAL STUDIES ===

@article{prompting2025practice,
  author = {Otten, Daniel and Stalnaker, Trevor and Wintersgill, Nathan and Chaparro, Oscar and Poshyvanyk, Denys},
  title = {Prompting in Practice: Investigating Software Developers' Use of Generative {AI} Tools},
  year = {2025},
  journal = {arXiv preprint arXiv:2510.06000},
  url = {https://arxiv.org/abs/2510.06000}
}

@article{anam2025prompteffectiveness,
  author = {Anam, Rizal Khoirul},
  title = {Prompt Engineering and the Effectiveness of Large Language Models in Enhancing Human Productivity},
  year = {2025},
  journal = {arXiv preprint arXiv:2507.18638},
  url = {https://arxiv.org/abs/2507.18638}
}

% === VENDOR DOCUMENTATION ===

@misc{anthropic2025evaltool,
  author = {{Anthropic}},
  title = {Using the Evaluation Tool},
  year = {2025},
  url = {https://docs.anthropic.com/en/docs/test-and-evaluate/eval-tool},
  note = {Documentation}
}

@misc{anthropic2025promptengineering,
  author = {{Anthropic}},
  title = {Prompt Engineering Overview},
  year = {2025},
  url = {https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview},
  note = {Documentation}
}

@misc{anthropic2025claude4bestpractices,
  author = {{Anthropic}},
  title = {Claude 4 Best Practices},
  year = {2025},
  url = {https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/claude-4-best-practices},
  note = {Documentation}
}

@misc{anthropic2025promptimprover,
  author = {{Anthropic}},
  title = {Use our prompt improver to optimize your prompts},
  year = {2025},
  url = {https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/prompt-improver},
  note = {Documentation}
}

@misc{anthropic2025toolsforagents,
  author = {{Anthropic}},
  title = {Writing Tools for Agents},
  year = {2025},
  url = {https://www.anthropic.com/engineering/writing-tools-for-agents},
  note = {Engineering blog post}
}

@misc{openai_evals_framework,
  author = {{OpenAI}},
  title = {{OpenAI} Evals Framework},
  year = {2023},
  url = {https://github.com/openai/evals},
  note = {GitHub repository}
}

% === APPLIED/DOMAIN-SPECIFIC ===

@article{itea2025llmtesting,
  author = {O'Brien, Karen},
  title = {Advancing the Test Science of {LLM}-enabled Systems: A Survey of Factors and Conditions that Matter Most},
  year = {2025},
  journal = {ITEA Journal},
  volume = {46},
  number = {3},
  url = {https://itea.org/journals/volume-46-3/advancing-the-test-science-of-llm-enabled-systems/}
}

@misc{liu_6ragevals,
  author = {Liu, Jason},
  title = {There Are Only 6 {RAG} Evals},
  year = {2025},
  url = {https://jxnl.co/writing/2025/05/19/there-are-only-6-rag-evals/},
  note = {Blog post}
}
